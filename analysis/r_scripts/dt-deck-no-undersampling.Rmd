---
title: "R Notebook"
author: Akshay Kale
output: html_notebook
description: Decision tree modeling of deck without undersampling.
---

#### *Libraries*
```{r}
library(lattice)
library(ISLR)
library(MASS)
library(caret)
library(tidyverse)
library(rpart)
library(plyr); library(dplyr)
library(caret)
library(rattle)                 # Fancy tree plot
library(rpart.plot) 
library(dplyr)
library(parallel)
library(Hmisc)
library(e1071)
library(pROC)
library(ggplot2)
library(rpart.plot)
library(VIM)
library(mice)

# Reading the dataset
nbi <- read.csv('../../../data/trees/decision-tree-dataset/decision_tree.csv')

# Select attributesk
df <- nbi %>% dplyr::select(adt.cat, adtt.cat, material, state, structure.number, structure.type, type.of.wearing.surface, current.deck, current.substructure, current.superstructure, total.deck.intervention, total.sub.intervention, total.super.intervention, deck.intervention.in.next.3.years, sub.intervention.in.next.3.years, super.intervention.in.next.3.years, precipitation, snowfall, freezethaw, score)
```

#### *Dataset to model deck of the bridges*
```{r}
# Select attributes
df_deck <- nbi %>% dplyr::select(adt.cat, adtt.cat, material, structure.type, type.of.wearing.surface, current.deck, current.substructure, current.superstructure, total.deck.intervention, total.sub.intervention, total.super.intervention,  precipitation, snowfall, freezethaw, score, deck.intervention.in.next.3.years)

# Remove null values
df_deck <- na.omit(df_deck)
```

#### *Preview of the data*
```{r}
head(df_deck)
```

#### *Training and testing Deck*
```{r}
target_variable <- 'deck.intervention.in.next.3.years'
index = createDataPartition(y=df_deck[[target_variable]], p=0.7, list=FALSE)
train.set = df_deck[index,]
test.set = df_deck[-index,]

positive_class = 'No'
negative_class = 'Yes' 

reset.seed <- function()
{
  # ensure results are repeatable
  set.seed(1337)
}
library(doParallel)
num_cores <- detectCores() #note: you can specify a smaller number if you want
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)

reset.seed()
model <- deck.intervention.in.next.3.years ~ adt.cat + adtt.cat + material + structure.type + type.of.wearing.surface + current.deck + current.substructure + current.superstructure + total.deck.intervention + total.sub.intervention + total.super.intervention +  precipitation + snowfall + freezethaw + score

tunelengths = seq(from=5, to=100, by=5)
list_sens <- c()
list_spec <- c()
list_f1 <-c()
list_tl <-c()
list_kappa <-c()
list_auc <- c()
probabilities_dt <- data.frame(No=double(), Yes=double())

for(tl in tunelengths) {
rtree_model = train( model,
                 data = train.set,
                 method = "rpart",
                 trControl = trainControl(method = "repeatedcv", search = 'random', repeats = 5,
                                          summaryFunction = twoClassSummary,
                                          classProbs = T, savePredictions = T),  tuneLength = tl,
                 metric='ROC')


rtree_model

# Predict on the training set
tree_class_test <- rtree_model%>% predict(newdata = test.set, type = 'raw')
tree_prob_test <- rtree_model%>% predict(newdata = test.set, type = 'prob')

# Confusion Matrix
metrics <- confusionMatrix(tree_class_test, test.set[[target_variable]])
metricsbyclass <- metrics$byClass

sens <- type.convert(metricsbyclass[1])
list_sens <- c(list_sens, sens)

spec <- type.convert(metricsbyclass[2])
list_spec <- c(list_spec, spec)

f1 <- type.convert(metricsbyclass[7])
list_f1 <- c(list_f1, f1)

tunelen <- tl
list_tl <- c(list_tl, tunelen)

kappa <- type.convert(metrics$overall[2])
list_kappa <- c(list_kappa, kappa)

# Confusion matrix
area <- roc(test.set[[target_variable]], tree_prob_test[[positive_class]], plot = TRUE, print.auc = TRUE, legacy.axes = TRUE)
list_auc <- c(list_auc, area$auc)

# rpart model
rpart.plot(rtree_model$finalModel)
filename <-paste('../../../data/trees/models/deck/tree-deck-no-undersample', toString(tl), '.csv', collapse = '')
write.csv(rpart.rules(rtree_model$finalModel, roundint=FALSE, clip.facs=TRUE), filename)

# Probability values
tree_prob_test['Tunelength'] <- rep(tl, length(tree_class_test))

# Concatenate
probabilities_dt <- bind_rows(probabilities_dt, tree_prob_test)

# metrics
metrics
}

df_metric_dt <- data.frame(list_sens, list_spec, list_f1, list_tl, list_kappa, list_auc)
names(df_metric_dt) <- c('Sensitivity', 'Specificity', 'F1','Tunelength', 'Kappa', 'AUC')

# Writing outputs
write.csv(probabilities_dt, '../../../data/trees/metrics/dt/tree-prob-deck-nou.csv')
write.csv(probabilities_dt, '../../../data/trees/metrics/dt/tree-metric-deck-nou.csv')
write.csv(df_metric_dt, '../../../data/trees/metrics/dt/tree-metric-deck-nou.csv')

df_metric_dt
probabilities_dt
```

```{r}
df_metric_dt
```

